from bs4 import BeautifulSoup
import urllib.request,time,pymongo

client = pymongo.MongoClient("localhost",27017)
ceshi = client["ceshi"]
url_list = ceshi["url_list3"]
item_info = ceshi["item_info3"]

def url_open(url):
    req=urllib.request.Request(url)
    req.add_header('User-Agent','Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36')
    reques=urllib.request.urlopen(req)
    html=reques.read().decode('utf-8',errors='replace')
    return html

def get_links_from(channel,pages,who_sells=0):
    list_view = "{}{}/pn{}/".format(channel,str(who_sells),str(pages))
    time.sleep(1)
    soup = BeautifulSoup(url_open(list_view),"lxml")
    if soup.find("td","t"):
        for link in soup.select("td.t a.t"):
            item_link = link.get("href").split("?")[0]
            jump = "jump"
            if jump in item_link:
                pass
            else:
                url_list.insert_one({"url": item_link})
                print(item_link)
                return item_link
    else:
        pass

def get_item_info(url):
    soup = BeautifulSoup(url_open(url),"lxml")
    no_longer_exist = "404" in str(soup.find("script",type="text/javascript").get("src")).split("/")
    if no_longer_exist:
        pass
    else:
        title = soup.title.text
        print(title)







